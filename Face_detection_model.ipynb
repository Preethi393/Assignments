{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8129d98c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:45.182866Z",
     "start_time": "2023-02-09T06:09:45.167346Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12372518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:47.182609Z",
     "start_time": "2023-02-09T06:09:45.187999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 11:39:45.194705: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 11:39:45.360316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-09 11:39:45.360337: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-09 11:39:46.135180: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 11:39:46.135252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 11:39:46.135261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ab0177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:47.191998Z",
     "start_time": "2023-02-09T06:09:47.187754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data generation for training data\n",
    "train_data = ImageDataGenerator(horizontal_flip=True,\n",
    "                                vertical_flip=False,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "063ea96b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:47.415615Z",
     "start_time": "2023-02-09T06:09:47.197026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10564 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Dataset\n",
    "train = train_data.flow_from_directory(directory ='/home/ubuntu/Desktop/Face_Recognition_DS_team/Train/',\n",
    "                                       target_size=(224, 224),\n",
    "                                       batch_size = 32,\n",
    "                                       class_mode =\"categorical\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2834aa0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:47.663105Z",
     "start_time": "2023-02-09T06:09:47.420641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10564 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation dataset\n",
    "validation = train_data.flow_from_directory(directory ='/home/ubuntu/Desktop/Face_Recognition_DS_team/Train/',\n",
    "                                       target_size=(224, 224),\n",
    "                                       batch_size = 32,\n",
    "                                       class_mode =\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fabb95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:47.685083Z",
     "start_time": "2023-02-09T06:09:47.666455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arun': 0,\n",
       " 'chaitanya': 1,\n",
       " 'laxmi': 2,\n",
       " 'navin': 3,\n",
       " 'papu': 4,\n",
       " 'priti': 5,\n",
       " 'rahul': 6,\n",
       " 'sangram': 7,\n",
       " 'sanket': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking classes\n",
    "train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf67c0",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc756ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:49.035901Z",
     "start_time": "2023-02-09T06:09:47.687563Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 11:39:47.723824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-09 11:39:47.723863: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-09 11:39:47.723896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu-Zako): /proc/driver/nvidia/version does not exist\n",
      "2023-02-09 11:39:47.724902: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e3c990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:49.049539Z",
     "start_time": "2023-02-09T06:09:49.038081Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c322b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:49.501164Z",
     "start_time": "2023-02-09T06:09:49.051678Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "#pooling layer \n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "#final dense layer\n",
    "outputs = keras.layers.Dense(9, activation = 'softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aff470e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:49.561644Z",
     "start_time": "2023-02-09T06:09:49.506462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 11529     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,269,513\n",
      "Trainable params: 11,529\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09b65cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:49.599761Z",
     "start_time": "2023-02-09T06:09:49.565305Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=['categorical_crossentropy'],metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812f7fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T06:09:49.614503Z",
     "start_time": "2023-02-09T06:09:49.604041Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Early stopping to avoid overfitting\n",
    "es = EarlyStopping(monitor = \"accuracy\",patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe7e34",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-02-09T06:09:45.225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 11:39:50.166927: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2023-02-09 11:39:53.051475: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2023-02-09 11:39:53.065196: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2023-02-09 11:39:53.183772: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n",
      "2023-02-09 11:39:53.241580: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 51380224 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 323s 35s/step - loss: 2.2099 - accuracy: 0.2219 - val_loss: 1.8952 - val_accuracy: 0.3321\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 306s 34s/step - loss: 1.6310 - accuracy: 0.4625 - val_loss: 1.4301 - val_accuracy: 0.5523\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 342s 38s/step - loss: 1.2870 - accuracy: 0.6313 - val_loss: 1.1040 - val_accuracy: 0.7181\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 557s 62s/step - loss: 1.1282 - accuracy: 0.7125 - val_loss: 0.9285 - val_accuracy: 0.7841\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 469s 52s/step - loss: 0.8811 - accuracy: 0.7875 - val_loss: 0.7910 - val_accuracy: 0.8233\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.8469"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train, validation_data = validation, epochs=20, callbacks = [es], steps_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861876bc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-02-09T06:09:45.227Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66d755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
