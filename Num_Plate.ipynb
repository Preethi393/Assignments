{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf5d76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:30.329465Z",
     "start_time": "2023-02-14T03:58:30.303925Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2cf182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:35.084582Z",
     "start_time": "2023-02-14T03:58:30.335258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 09:28:30.358189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 09:28:31.000142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-14 09:28:31.000170: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-14 09:28:32.784114: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 09:28:32.784234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 09:28:32.784248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a4bbb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:35.094240Z",
     "start_time": "2023-02-14T03:58:35.091184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data generation for training data\n",
    "train_data = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69c0634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:35.102036Z",
     "start_time": "2023-02-14T03:58:35.096890Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_data = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016e7254",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:35.308460Z",
     "start_time": "2023-02-14T03:58:35.104088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10880 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Dataset\n",
    "train = train_data.flow_from_directory(directory ='/home/ubuntu/Desktop/sep_data_final/sep_data/train/',\n",
    "                                       target_size=(224, 224),\n",
    "                                       batch_size = 32,\n",
    "                                       shuffle = True,\n",
    "                                       class_mode =\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1c597a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:35.363089Z",
     "start_time": "2023-02-14T03:58:35.310694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2050 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation dataset\n",
    "validation = validation_data.flow_from_directory(directory ='/home/ubuntu/Desktop/sep_data_final/sep_data/val/',\n",
    "                                       target_size=(224, 224),\n",
    "                                       batch_size = 32,\n",
    "                                       shuffle = False,\n",
    "                                       class_mode =\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29cf5538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:35.370040Z",
     "start_time": "2023-02-14T03:58:35.365871Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b1e45e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:37.258822Z",
     "start_time": "2023-02-14T03:58:35.371857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 09:28:35.408107: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-14 09:28:35.408136: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-14 09:28:35.408158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu-Zako): /proc/driver/nvidia/version does not exist\n",
      "2023-02-14 09:28:35.409090: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "res_net = keras.applications.ResNet50V2(\n",
    "    weights = \"imagenet\",\n",
    "    input_shape = (224,224,3),\n",
    "    include_top = False)\n",
    "\n",
    "res_net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1b422c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:37.953715Z",
     "start_time": "2023-02-14T03:58:37.263553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add ResNet model to sequential model\n",
    "model.add(res_net)\n",
    "\n",
    "# Convert the model into 1d array\n",
    "model.add(Flatten())\n",
    "\n",
    "# First fully connnected layer with dropout and batchnormalization\n",
    "model.add(Dense(units = 128,activation = \"relu\"))\n",
    "model.add(Dropout(0.20))\n",
    "    \n",
    "# Second fully connnected layer with dropout and batchnormalization\n",
    "model.add(Dense(units = 64,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "# Third fully connnected layer with dropout\n",
    "model.add(Dense(units = 32,activation = \"relu\"))\n",
    "model.add(Dropout(0.20))\n",
    "    \n",
    "# Final output layer with softmax activation function\n",
    "model.add(Dense(units = 36,activation = \"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07e4f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:37.989906Z",
     "start_time": "2023-02-14T03:58:37.957262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               12845184  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                1188      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,421,764\n",
      "Trainable params: 12,856,836\n",
      "Non-trainable params: 23,564,928\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c465ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:38.010509Z",
     "start_time": "2023-02-14T03:58:37.991866Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss=['categorical_crossentropy'],metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1a8021d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T03:58:38.015962Z",
     "start_time": "2023-02-14T03:58:38.012632Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Early stopping to avoid overfitting\n",
    "es = EarlyStopping(monitor = \"accuracy\",patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458f978d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T10:40:08.218838Z",
     "start_time": "2023-02-14T03:58:38.018364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "340/340 [==============================] - 2683s 8s/step - loss: 1.0927 - accuracy: 0.7429 - val_loss: 0.3733 - val_accuracy: 0.9298\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 2617s 8s/step - loss: 0.2419 - accuracy: 0.9438 - val_loss: 0.2666 - val_accuracy: 0.9478\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 2247s 7s/step - loss: 0.1293 - accuracy: 0.9665 - val_loss: 0.2327 - val_accuracy: 0.9561\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 2489s 7s/step - loss: 0.0790 - accuracy: 0.9813 - val_loss: 0.2567 - val_accuracy: 0.9502\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 2411s 7s/step - loss: 0.0667 - accuracy: 0.9827 - val_loss: 0.2622 - val_accuracy: 0.9590\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 2279s 7s/step - loss: 0.0588 - accuracy: 0.9839 - val_loss: 0.2659 - val_accuracy: 0.9571\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 2213s 7s/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.2815 - val_accuracy: 0.9580\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 2351s 7s/step - loss: 0.0392 - accuracy: 0.9889 - val_loss: 0.3343 - val_accuracy: 0.9512\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 2297s 7s/step - loss: 0.0403 - accuracy: 0.9886 - val_loss: 0.3282 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 2270s 7s/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 0.3333 - val_accuracy: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53ac2e3b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, validation_data = validation, epochs = 10, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "245d566c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T10:40:13.765606Z",
     "start_time": "2023-02-14T10:40:08.307622Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6534b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
